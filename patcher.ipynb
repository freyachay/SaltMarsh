{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from osgeo import gdal\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config Values\n",
    "patch_size = 200\n",
    "step_size = 200\n",
    "DESTINATION = 'Users/freyachay/Documents/Stanford/junior/SALT_MARSHES/training/'\n",
    "INPUT_DIR = '/Users/freyachay/Documents/Stanford/junior/SALT_MARSHES/git/'\n",
    "INPUT_NAMES = ['bayArea_mosaic.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credit to nshaud \n",
    "# (https://github.com/nshaud/DeepNetsForEO/blob/master/notebooks/Image%20extraction.ipynb) for general outline of making patches.\n",
    "def sliding_window(image, patch_size, step_size):\n",
    "    \"\"\"Extract chips using a sliding window\n",
    "    \n",
    "    Args:\n",
    "        image (numpy array): The image to be processed.\n",
    "        stride (int): The sliding window stride.\n",
    "        patch_size(int, int, optional): The patch size.\n",
    "\n",
    "    Returns:\n",
    "        list: list of patches with patch_size dimensions\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    discarded = 0\n",
    "    for i in range(0, image.shape[0], step_size):\n",
    "        for j in range(0, image.shape[1], step_size):\n",
    "            new_patch = image[:, i:i+patch_size, j:j+patch_size]\n",
    "            if new_patch.shape[1] == new_patch.shape[2] == patch_size:\n",
    "                patches.append(new_patch)\n",
    "            else:\n",
    "                discarded += 1\n",
    "    return patches, discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# takes image in numpy arr form\n",
    "def make_patches(image, trans, proj):\n",
    "    patches, num_discarded = sliding_window(arr, patch_size, step_size)\n",
    "    bands, rows, cols = patches[0].shape\n",
    "    \n",
    "    for i in range(len(patches)):\n",
    "        outfile = \"tile_\"+ str(i) + \".tif\"\n",
    "        print outfile\n",
    "        patch = patches[i]\n",
    "        # Create the file, using the information from the original file\n",
    "        outdriver = gdal.GetDriverByName(\"GTiff\")\n",
    "        outdata   = outdriver.Create(str(outfile), rows, cols, bands, gdal.GDT_Int16) #### Might need to be int16\n",
    "\n",
    "        # Georeference the image\n",
    "        outdata.SetGeoTransform(trans)\n",
    "\n",
    "        # Write projection information\n",
    "        outdata.SetProjection(proj)\n",
    "\n",
    "        # Write the array to the file, which is the original array in this example\n",
    "        for i in range(1,bands+1):\n",
    "            outdata.GetRasterBand(i).WriteArray(patch[i-1], 0, 0)\n",
    "            outdata.GetRasterBand(i).FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24200, 19400, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get image as array\n",
    "\n",
    "mosaic_path = INPUT_DIR + \"bayArea_mosaic.tif\"\n",
    "# labels_path = INPUT_DIR + \"bayArea_mosaic_labels.tif\"\n",
    "\n",
    "try:\n",
    "    data = gdal.Open(mosaic_path)\n",
    "except RuntimeError, e:\n",
    "    print 'Unable to open ' + mosaic_path +':'\n",
    "    print e\n",
    "trans = data.GetGeoTransform()\n",
    "proj = data.GetProjection()\n",
    "bands_data = []\n",
    "for b in range(1, data.RasterCount+1):\n",
    "    band = data.GetRasterBand(b)\n",
    "    bands_data.append(band.ReadAsArray())\n",
    "\n",
    "bands_data = np.dstack(bands_data)\n",
    "rows, cols, n_bands = bands_data.shape\n",
    "print (rows,cols, n_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Credit to  Carlos De La Torre\n",
    "# http://www.machinalis.com/blog/python-for-geospatial-data-processing/?utm_content=bufferf65db&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer\n",
    "\n",
    "def create_mask_from_vector(vector_data_path, cols, rows, geo_transform,\n",
    "                            projection, target_value=1):\n",
    "    \"\"\"Rasterize the given vector (wrapper for gdal.RasterizeLayer).\"\"\"\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    layer = data_source.GetLayer(0)\n",
    "    driver = gdal.GetDriverByName('MEM')  # In memory dataset\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[target_value])\n",
    "    return target_ds\n",
    "\n",
    "\n",
    "def vectors_to_raster(path, rows, cols, geo_transform, projection):\n",
    "    \"\"\"Rasterize the vectors in the given directory in a single image.\"\"\"\n",
    "    labeled_pixels = np.zeros((rows, cols))\n",
    "    ds = create_mask_from_vector(path, cols, rows, geo_transform,\n",
    "                                 projection, target_value=1)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    labeled_pixels += band.ReadAsArray()\n",
    "    ds = None\n",
    "    return labeled_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get labels as array \n",
    "shapefile = INPUT_DIR + \"bayArea_mosaic_label_clipped.shp\"\n",
    "labeled_pixels = vectors_to_raster(shapefile, rows, cols, trans,proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "\n",
    "\n",
    "EXPERIMENTING BELOW WITH SIMPLE CLASSIFICATION\n",
    "TODO: Implement sharding + saving as tfrecords\n",
    "\n",
    "\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate marsh and other pixels\n",
    "is_marsh = (labeled_pixels !=0)\n",
    "marsh_data = bands_data[is_marsh]\n",
    "other_data = bands_data[~is_marsh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/freyachay/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n",
      "/Users/freyachay/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375583999, 5)\n",
      "(375583999,)\n",
      "[ 1.  1.  1. ...,  0.  0.  0.]\n",
      "(93896001, 5)\n",
      "(93896001,)\n",
      "[ 1.  1.  1. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Create train and validation pixel sets (80% / 20% split)\n",
    "\n",
    "marsh_train_indices = np.random.choice(np.arange(marsh_data.shape[0]), marsh_data.shape[0] * 0.8, replace=False)\n",
    "marsh_train = marsh_data[marsh_train_indices, :]\n",
    "marsh_val = np.delete(marsh_data, marsh_train_indices, axis=0)\n",
    "\n",
    "other_train_indices = np.random.choice(np.arange(other_data.shape[0]), other_data.shape[0] * 0.8, replace=False)\n",
    "other_train = other_data[other_train_indices, :]\n",
    "other_val = np.delete(other_data, other_train_indices, axis=0)\n",
    "\n",
    "train_data = np.vstack((marsh_train, other_train))\n",
    "train_labels = np.concatenate((np.ones(marsh_train.shape[0]), np.zeros(other_train.shape[0])))\n",
    "\n",
    "val_data = np.vstack((marsh_val, other_val))\n",
    "val_labels = np.concatenate((np.ones(marsh_val.shape[0]), np.zeros(other_val.shape[0])))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_labels)\n",
    "\n",
    "print(val_data.shape)\n",
    "print(val_labels.shape)\n",
    "print(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/freyachay/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n",
      "/Users/freyachay/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Downsize for easy experimentation\n",
    "num_train = train_labels.size\n",
    "ex_train_indices = np.random.choice(np.arange(num_train), num_train * 0.00001, replace=False)\n",
    "ex_train_data = train_data[ex_train_indices,:]\n",
    "ex_train_labels = train_labels[ex_train_indices]\n",
    "\n",
    "num_val = val_labels.size\n",
    "ex_val_indices = np.random.choice(np.arange(num_val), num_val * 0.00001, replace=False)\n",
    "ex_val_data = val_data[ex_val_indices,:]\n",
    "ex_val_labels = val_labels[ex_val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% marsh train pixels: 3.51331660431\n",
      "% marsh val pixels: 3.51331682379\n",
      "\n",
      "(3755, 5)\n",
      "(3755,)\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "(938, 5)\n",
      "(938,)\n",
      "\n",
      "% marsh ex_train pixels: 3.88814913449\n",
      "% marsh ex_val pixels: 3.94456289979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"% marsh train pixels: \" + str(100 * float(marsh_train_indices.size) /(marsh_train_indices.size + other_train_indices.size)))\n",
    "print (\"% marsh val pixels: \"+ str(100 * (float(marsh_val.shape[0]) /(marsh_val.shape[0] + other_val.shape[0]))))\n",
    "print (\"\")\n",
    "\n",
    "print(ex_train_data.shape)\n",
    "print(ex_train_labels.shape)\n",
    "print(ex_train_labels)\n",
    "\n",
    "print(ex_val_data.shape)\n",
    "print(ex_val_labels.shape)\n",
    "# print(ex_val_labels)\n",
    "print(\"\")\n",
    "\n",
    "print (\"% marsh ex_train pixels: \" + str(100* sum(ex_train_labels)/ex_train_labels.size))\n",
    "print (\"% marsh ex_val pixels: \"+ str(100* sum(ex_val_labels)/ex_val_labels.size))\n",
    "print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root = \"/Users/freyachay/Documents/Stanford/junior/SALT_MARSHES/baselineData/\"\n",
    "# np.savetxt( root + \"train.csv\", np.column_stack((train_labels,train_data)), delimiter=\" \")\n",
    "# np.savetxt( root + \"val.csv\", np.column_stack((val_labels,val_data)), delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load data from CSV files\n",
    "\n",
    "# train = numpy.loadtxt(root + \"train.csv\")\n",
    "# train_label = train[:,0]\n",
    "# train_data = train[:,1:]\n",
    "\n",
    "# val = numpy.loadtxt(root + \"val.csv\")\n",
    "# val_label = val[:,0]\n",
    "# val_data = val[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per pixel Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_jobs=-1)\n",
    "classifier.fit(ex_train_data, ex_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix:\n",
      "[[899   2]\n",
      " [ 29   8]]\n",
      "Classification accuracy: 0.966951\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = classifier.predict(ex_val_data)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confussion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(ex_val_labels, predicted_labels))\n",
    "\n",
    "# print(\"Classification report:\\n%s\" %\n",
    "#       metrics.classification_report(ex_val_labels, predicted_labels,\n",
    "#                                     target_names=[]))\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(ex_val_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix:\n",
      "[[898   3]\n",
      " [ 28   9]]\n",
      "Classification accuracy: 0.966951\n"
     ]
    }
   ],
   "source": [
    "# Per pixel Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\")\n",
    "classifier.fit(ex_train_data, ex_train_labels)\n",
    "\n",
    "predicted_labels = classifier.predict(ex_val_data)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(ex_val_labels, predicted_labels))\n",
    "\n",
    "# print(\"Classification report:\\n%s\" %\n",
    "#       metrics.classification_report(ex_val_labels, predicted_labels,\n",
    "#                                     target_names=[]))\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(ex_val_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix:\n",
      "[[895   6]\n",
      " [ 28   9]]\n",
      "Classification accuracy: 0.963753\n"
     ]
    }
   ],
   "source": [
    "# Per pixel Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced_subsample\")\n",
    "classifier.fit(ex_train_data, ex_train_labels)\n",
    "\n",
    "predicted_labels = classifier.predict(ex_val_data)\n",
    "print(\"Confusion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(ex_val_labels, predicted_labels))\n",
    "\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(ex_val_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[901   0]\n",
      " [ 37   0]]\n",
      "Classification accuracy: 0.960554\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC(gamma=2, C=5000.)\n",
    "classifier.fit(ex_train_data, ex_train_labels)\n",
    "\n",
    "predicted_labels = classifier.predict(ex_val_data)\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(ex_val_labels, predicted_labels))\n",
    "\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(ex_val_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[856  45]\n",
      " [ 13  24]]\n",
      "Classification accuracy: 0.938166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifier = QuadraticDiscriminantAnalysis()\n",
    "classifier.fit(ex_train_data, ex_train_labels)\n",
    "\n",
    "predicted_labels = classifier.predict(ex_val_data)\n",
    "\n",
    "print(\"Confusion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(ex_val_labels, predicted_labels))\n",
    "\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(ex_val_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
